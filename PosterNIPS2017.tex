%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% baposter Landscape Poster
% LaTeX Template
% Version 1.0 (11/06/13)
%
% baposter Class Created by:
% Brian Amberg (baposter@brian-amberg.de)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[landscape,a0paper,fontscale=0.35]{baposter} % Adjust the font scale/size here : fontscale=0.285
%\usepackage{textpos}
\usepackage[frenchb]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{graphicx} % Required for including images
%\graphicspath{{Figures/}} % Directory in which figures are stored
\usepackage{amsmath} % For typesetting math
\usepackage{amsthm}
\usepackage{amssymb} % Adds new symbols to be used in math mode
\usepackage{booktabs} % Top and bottom rules for tables
\usepackage{enumitem} % Used to reduce itemize/enumerate spacing
\usepackage{palatino} % Use the Palatino font
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{multicol} % Required for multiple columns
\usepackage{tikz} % Required for flow chart
\usetikzlibrary{shapes,arrows} % Tikz libraries required for the flow chart in the template
%\usepackage{dsfont}
%\usepackage{listings}
\usepackage{subfigure}
\usepackage{color}
%\usepackage{nth}
%\usepackage{a4wide}
\usepackage{graphicx,color}
\usepackage{array}
%\usepackage[nottoc, notlof, notlot]{tocbibind}
\usepackage{subfigure}
\usetikzlibrary{arrows,shapes,positioning,calc}
%\definecolor{CPU}{RGB}{30, 167, 223}
%\definecolor{CPU}{RGB}{8, 138, 104}
\definecolor{gris}{gray}{0.9}
\usepackage{geometry}
\geometry{left=0.9cm,right=0.9cm,bottom=0.9cm,top=0.9cm,centering}
%\usepackage{subfig}
\usepackage{float}
\usepackage{multicol}
\usepackage{enumitem,rotating}
\usepackage{bbm}
\usepackage{tcolorbox}


\newcommand{\sidecap}[1]{ {\begin{sideways}\parbox{0.2\textwidth}{\centering #1}\end{sideways}} }

\theoremstyle{plain}
\newtheorem*{thm}{Theorem}
%\theoremstyle{definition}
%\newtheorem*{defi}[thm]{Definition}
\theoremstyle{plain}
\newtheorem*{prop}{Properties}
\theoremstyle{plain}
\newtheorem*{hyp}{Assumption}
\theoremstyle{plain}
\newtheorem*{proposition}{Proposition}

\setlength{\columnsep}{1.5em} % Slightly increase the space between columns
\setlength{\columnseprule}{0mm} % No horizontal rule between columns

\definecolor{lightred}{rgb}{0.5 0 0}

\newcommand{\compresslist}{ % Define a command to reduce spacing within itemize/enumerate environments, this is used right after \begin{itemize} or \begin{enumerate}
\setlength{\itemsep}{1pt}
\setlength{\parskip}{0pt}
\setlength{\parsep}{0pt}
}

\definecolor{CPU}{RGB}{0, 153, 125} % Defines the color used for content box headers




% Math operators
\newcommand{\scal}[2]{\left\langle #1 , #2 \right\rangle}
\DeclareMathOperator{\IR}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\One}{\mathbbm{1}}
\DeclareMathOperator{\Ccal}{\mathcal{C}}
\DeclareMathOperator{\logsumexp}{logsumexp}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\KL}{KL}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\renewcommand{\epsilon}{\varepsilon}


\begin{document}

\begin{poster}
{
background=plain,
headershade=plain,
headerborder=closed, % Adds a border around the header of content boxes
colspacing=0.8em, % Column spacing
bgColorOne=gris, % Background color for the gradient on the left side of the poster
bgColorTwo=gris, % Background color for the gradient on the right side of the poster
borderColor=CPU, % Border color
headerColorOne=CPU, % Background color for the header in the content boxes (left side)
headerColorTwo=CPU, % Background color for the header in the content boxes (right side)
headerFontColor=white, % Text color for the header text in the content boxes
boxColorOne=white, % Background color of the content boxes
textborder=roundedsmall, % Format of the border around content boxes, can be: none, bars, coils, triangles, rectangle, rounded, roundedsmall, roundedright or faded
eyecatcher=true, % Set to false for ignoring the left logo in the title and move the title left
headerheight=0.10\textheight, % Height of the header
headershape=rounded, % Specify the rounded corner in the content box headers, can be: rectangle, small-rounded, roundedright, roundedleft or rounded
headerfont=\Large\bf\textsc, % Large, bold and sans serif font in the headers of content boxes
%textfont={\setlength{\parindent}{1.5em}}, % Uncomment for paragraph indentation
linewidth=1.8pt, % Width of the border lines around content boxes
columns=3,
}
%----------------------------------------------------------------------------------------
%	TITLE SECTION 
%----------------------------------------------------------------------------------------
%
{\includegraphics[height=6em]{logo_ens_psl.png}} % First university/lab logo on the left
{\bf Overrelaxed Sinkhorn--Knopp algorithm\\ for regularized optimal transport\vspace{0.2em}} 
{{Alexis Thibault, L\'enaïc Chizat, Charles Dossal and  Nicolas Papadakis}} % Author names and institution
{\includegraphics[height=6em]{logo_imb.png}} % Second university/lab logo on the right

%----------------------------------------------------------------------------------------
%	RESEARCH
%----------------------------------------------------------------------------------------

% Introduction

\headerbox{Introduction}{name=intro,column=0,span=2}{
	\begin{minipage}{0.55\textwidth}
		\begin{itemize}
			\item Optimal Transport: efficient and flexible tool to compare two probability distributions.
			
			\item The fast \textbf{Sinkhorn--Knopp} algorithm (SK) can be used to numerically calculate an approximate solution [Cuturi, 2013].
			
			\item Our contribution: new algorithm based on \textbf{overrelaxation} of SK.
			
			\item Always converges to the solution
			
			\item Adaptive choice of parameters
			
			\item Converges \textbf{between 2 and 20 times faster} than SK, with almost the same cost per iteration, and other nice properties.
		\end{itemize}
	\end{minipage}
	\begin{minipage}{0.45\textwidth}
		\centering
		\begin{tcolorbox}[width=0.99\textwidth,/tcb/size=small, /tcb/top=2.0mm]
			\centering
			\begin{tabular}{c c c c}
				\includegraphics[height=3cm]{1d_interp_mu} &
				\includegraphics[height=3cm]{1d_interp_0_2} &
				\includegraphics[height=3cm]{1d_interp_2} &
				\includegraphics[height=3cm]{1d_interp_18} \\
				&
				$\epsilon = 5$ &
				$\epsilon = 0.5$ &
				$\epsilon = 0.02$
			\end{tabular}
			\captionof{figure}{Regularized optimal transport maps for decreasing regularization parameter $\epsilon$.} \label{fig:1d_ot}
		\end{tcolorbox}
	\end{minipage}
}




%----------------------------------------------------------------------------------------
%	
%----------------------------------------------------------------------------------------

\headerbox{Overrelaxation}{name=overrelaxation,column=1,below=intro}{
\begin{minipage}{0.6\textwidth}
	\begin{tcolorbox}[size=small, top=2mm]
		\centering
		\begin{tabular}{c c}
		\input{schema_b} &
		\input{schema_c} \\
		SK &
		Overrelaxed SK
		\end{tabular}
	\captionof{figure}{For small regularization $\epsilon$, the SK algorithm converges slowly, whereas the overrelaxed SK algorithm converges with a better rate}
	\end{tcolorbox}
\end{minipage}
\begin{minipage}{0.4\textwidth}
	\textbf{Overrelaxed projections}: elevate the scaling factors to some power $\theta \in \IR$.
	\begin{align*}\label{or_scaling}
	P_{\Ccal_1}^\theta(\gamma) &= \diag(a)^\theta \gamma\\
	P_{\Ccal_2}^\theta(\gamma) &= \gamma \diag(b)^\theta \nonumber .
	\end{align*}
	(element-wise exponentiation)
	
	
	Iterative overrelaxed projections \textbf{converge locally} for any $\theta \in (0,2)$.
	In the global, non-euclidean setting, we use an additional criterion based on a Lyapunov function.
\end{minipage}

Overrelaxation modifies the eigenvalues of the linearized operator in a predictable way: if SK converges at rate $1-\eta$, then the optimal asymptotic overrelaxation parameter is $\theta_0 = \frac{2}{1+\sqrt{\eta}}$, for which the convergence rate is $\frac{1-\sqrt{\eta}}{1+\sqrt{\eta}}$.
}





%----------------------------------------------------------------------------------------
% Main result
%----------------------------------------------------------------------------------------

\headerbox{Lyapunov Function}{name=lyapunov,column=2}{
	To ensure convergence of iterative overrelaxed Bregman projections, we assert the decrease of a \textbf{Lyapunov function}.
	\begin{tcolorbox}[size=small]
    	Choose $F(\gamma)$ continuous, coercive function whose unique minimizer is $\gamma^*$.\\
    	Choose $\theta_1(\gamma)$, $\theta_2(\gamma)$ continuous functions, such that
    	\begin{equation*}\label{eq:cond_theta_k}
    	\forall k \in \{1,2\}, \, \forall \gamma \notin \Ccal_k,\quad\quad
    	F(P_{\Ccal_k}^{\theta_k(\gamma)}(\gamma)) < F(\gamma).
    	\end{equation*}
    	Alternately iterate $P_{\Ccal_1}^{\theta_1}$ and $P_{\Ccal_2}^{\theta_2}$, starting from $\gamma^0 = e^{-c/\epsilon}$.
    	This process converges to $\gamma^*$.
    \end{tcolorbox}
    Our choice of Lyapunov function is: $F(\gamma) := \KL(\gamma^*,\gamma)$.
    Note that this function decreases for regular Bregman projections.
    
    \begin{minipage}{0.65\textwidth}
    	\vspace{0.6em}
    	Differences of $F$ can be calculated:
    	\begin{gather*} \label{eq:kl_diff_scal}
    	F(\gamma) - F(P^\theta_{\Ccal_k}(\gamma)) = 
    	\scal{\mu^k}{\varphi_\theta \left((A_k \gamma) \oslash \mu^k \right)}.\\
    	\varphi_\theta(x) = x(1-x^{-\theta}) - \theta \log x
    	\end{gather*}
    	We want this difference to be positive. A sufficient condition is that every coordinate of $\varphi_\theta \left((A_k \gamma) \oslash \mu^k \right)$ be positive.
    	\begin{gather*}
    	\Theta^*(u) := \max \left\{\theta \mid \varphi_\theta(u) \ge 0 \right\}
    	\\
    	\Theta(u) := clip_{[1,\theta_0]}(\Theta^*(\min u)-\delta)\\
    	k \in \{1,2\}, \quad \theta_k (\gamma) := \Theta((A_k \gamma) \oslash \mu^k)
    	\end{gather*}
    \end{minipage}
	\begin{minipage}{0.34\textwidth}
		\begin{tcolorbox}[size=small]
			\centering
			\includegraphics[width=\textwidth]{images/cvgce_zone_2.png}
			\captionof{figure}{
				Function $\varphi_\theta(x)$ is positive above the red line, negative below.}
		\end{tcolorbox}
	\end{minipage}
This adaptive choice allows to choose the overrelaxation parameter $\theta_0$ that is used asymptotically. 
}



%----------------------------------------------------------------------------------------
%	Bootstrap
%----------------------------------------------------------------------------------------

\headerbox{Experiments}{name=expe,below=overrelaxation,column=1,span=2}{
	\begin{minipage}{\textwidth}
		We compare our algorithm to SK algorithm on two different settings of size $100 \times 100$.
		In both experimental settings, our algorithm wins by a factor above $20$ for small $\epsilon$.
	\end{minipage}
	\begin{minipage}{0.6\textwidth}
		\begin{tcolorbox}[size=small]
			\begin{minipage}{0.5\textwidth}
				\centering
				\includegraphics[width=0.9\textwidth]{images/speedratio_image}\\
				(a) Squared euclidean norm on $[0,1]$. Marginals randomly generated, piecewise constant.
			\end{minipage}%
			\begin{minipage}{0.5\textwidth}
				\centering
				\includegraphics[width=0.9\textwidth]{images/speedratio_ML}\\
				(b) Random cost, uniform marginals.
			\end{minipage}
		\captionof{figure}{Relative speed of our algorithm compared to Sinkhorn--Knopp, for various values of $\epsilon$}
		\end{tcolorbox}
	\end{minipage}
	\begin{minipage}{0.4\textwidth}
		\begin{tcolorbox}[size=small]
			\centering
			\includegraphics[width=0.89\textwidth]{typical_convergence_2} \\
			\captionof{figure}{Typical behavior of the algorithm: value of the Lyapunov function and of the overrelaxation parameters during the iterations.}
		\end{tcolorbox}
	\end{minipage}
}



%----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------


\headerbox{References}{name=references,below=lyapunov,column=2,bottomaligned=overrelaxation}{
	\scriptsize
	\begin{multicols}{2}
		\textbf{[Cuturi, 2013]} M. Cuturi. Sinkhorn distances: Lightspeed computation of optimal transport. {\it Advances in Neural Information Processing Systems 26}, 2013.
		
		\textbf{[Benamou et al., 2015]} Benamou, J.-D., Carlier, G., Cuturi, M., Nenna, L., and Peyr\'e, G. (2015).
		{\it Iterative Bregman projections for regularized transportation problems.} SIAM Journal on Scientific
		Computing, 37(2):A1111–A1138.
		
		\textbf{[Sinkhorn, 1964]} Sinkhorn, R. (1964). {\it A relationship between arbitrary positive matrices and doubly stochastic matrices.} The annals of mathematical statistics, 35(2):876–879.
		
		\textbf{[Schmitzer, 2016]} Schmitzer, B. 2016. Stabilized sparse scaling algorithms for entropy regularized transport problems. {\it arXiv preprint arXiv:1610.06519.}
	\end{multicols}
}


%----------------------------------------------------------------------------------------
%	Notations and definitions
%----------------------------------------------------------------------------------------

\headerbox{Sinkhorn-Knopp Algorithm}{name=Sinkhorn,column=0,below=intro,bottomaligned=expe}{
	Entropic regularization of optimal transport:
	\begin{equation*} \label{eq:problem}
	\gamma^* = \argmin_{\gamma \in \Ccal_1 \cap \Ccal_2}
	\scal{c}{\gamma} + \epsilon \KL(\gamma,\One).
	\end{equation*}
	Marginal contraint sets $\Ccal_1$ and $\Ccal_2$ correspond to two discrete measures $\mu^1$ and $\mu^2$, and $\KL$ is the Kullback--Leibler divergence.
	\begin{gather*}
	\Ccal_1 = \left\{ \gamma \mid A_1 \gamma = \mu^1 \right\},
	\quad\quad\quad
	\Ccal_2 = \left\{ \gamma \mid A_2 \gamma = \mu^2 \right\}.\\
	\KL(\gamma,\xi) = \sum_{i,j} \gamma_{i,j} \left( \log \left( \frac{\gamma_{i,j}}{\xi_{i,j}} \right) -1  \right) + \sum_{i,j} \xi_{i,j}.
	\end{gather*}
	\begin{minipage}{0.55\textwidth}
		As problem (\ref{eq:problem}) is strictly convex, it has exactly one solution, that can be written equivalently as the \textbf{Bregman projection} of $\gamma^0 = e^{-c/\epsilon}$ onto a convex set:
		\begin{gather*}
		P_{\Ccal}(\xi) := \argmin_{\gamma \in \Ccal} \KL(\gamma,\xi),\\
		\text{(\ref{eq:problem})} \quad \Longleftrightarrow \quad \gamma^* = P_{\Ccal_1 \cap \Ccal_2}(\gamma^0).
		\end{gather*}
		Whereas projecting onto $\Ccal_1 \cap \Ccal_2$ is challenging, projecting onto $\Ccal_1$ or $\Ccal_2$ individually is simply performed by \textbf{scaling the rows or columns} of the matrix.
		Operator $\oslash$ denotes element-wise division:
		\begin{align*}\label{scaling}
		P_{\Ccal_1}(\gamma) &= \diag(a) \gamma &\text{with}\quad
		a &=  {\mu^1}\oslash{A_1 \gamma} \\
		P_{\Ccal_2}(\gamma) &= \gamma \diag(b) &\text{with}\quad
		b &= {\mu^2}\oslash{A_2 \gamma}\nonumber
		\end{align*}
	\end{minipage}
	\begin{minipage}{0.44\textwidth}
		\begin{tcolorbox}[/tcb/size=small, /tcb/top=2.0mm]
			\centering
			\input{schema_a}
			\captionof{figure}{The Sinkhorn--Knopp algorithm iterates Bregman projections on the two constraint sets.}
		\end{tcolorbox}
	\end{minipage}
	
	\vspace{0.6em}
	\textbf{Sinkhorn--Knopp algorithm:}
	\begin{equation*}
	\lim P_{\Ccal_2}\circ P_{\Ccal_1} \circ \ldots \circ P_{\Ccal_2} \circ P_{\Ccal_1} (\gamma^0) = \gamma^*
	\end{equation*}
	This algorithm \textbf{converges linearly}: if we denote by $\gamma^\ell = (P_{\Ccal_2} \circ P_{\Ccal_1})^{(\ell)}(\gamma^0)$ the $\ell$-th iterate, then
	\[ \norm{\gamma^\ell - \gamma^*} = \mathcal{O}\left((1-\eta)^\ell \right) , \quad \eta > 0 \]
}



\end{poster}

\end{document}