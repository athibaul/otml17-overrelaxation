\documentclass[compress]{beamer}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{xcolor} % Pour colorer des symboles dans les Ã©quations
\usepackage{bbm}

\usepackage{tikz}
\usepackage{cite}

% Math operators
\newcommand{\scal}[2]{\left\langle #1 , #2 \right\rangle}
\DeclareMathOperator{\IR}{\mathbb{R}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\One}{\mathbbm{1}}
\DeclareMathOperator{\Ccal}{\mathcal{C}}
\DeclareMathOperator{\logsumexp}{logsumexp}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\KL}{KL}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\renewcommand{\epsilon}{\varepsilon}

\newtheorem{proposition}{Proposition}

\title[Overrelaxed SK Algorithm]{Overrelaxed Sinkhorn--Knopp Algorithm for Regularized Optimal Transport}

%
\author[A. THIBAULT]{
	Alexis THIBAULT, 
	L\'ena\"ic CHIZAT,\\
	Charles DOSSAL,
	Nicolas PAPADAKIS
}
\institute[OTML'17]{Optimal Transport and Machine Learning workshop \\ NIPS 2017}
\date{December 9, 2017}

\usetheme{CambridgeUS}


\begin{document}

\titlepage

\begin{frame}
{Context} 
\begin{itemize}
\item Fast computation of regularized Optimal Transport with the Sinkhorn--Knopp algorithm  {\color{blue}[Cuturi, 2013]}
\item Slower algorithm for small values of the regularization parameter $\epsilon$
\end{itemize}
\uncover<2>{
\tableofcontents}
% We'll be looking at a way of accelerating an algorithm, called the SK algorithm, whose goal is to calculate the solution of the regularized optimal transport problem. The principle of overrelaxation has been shown to successfully accelerate this algorithm. However, there is no proof in the literature that the proposed algorithm always converges, and no automated choice of parameters.
% In our paper, we suggest a way of ensuring global convergence. This is done simply by choosing the overrelaxation parameters at each step of the algorithm so that a given function decreases. We will motivate our choice of function with numerical results.
\end{frame}

\section[Overrelaxing SK]{Acceleration of  the Sinkhorn--Knopp algorithm }

\subsection[SK algorithm]{The Sinkhorn--Knopp algorithm}
\begin{frame}{Regularized optimal transport}
Entropic regularization of optimal transport:
\begin{equation*} \label{eq:problem}
\gamma^* = \argmin_{\gamma \in \IR^{n_1 n_2}_+ \cap \Ccal_1 \cap \Ccal_2}
	\scal{c}{\gamma} + \epsilon \KL(\gamma,\One)
\end{equation*}
\pause
Constraint sets:
\begin{align*}
\Ccal_1 &= \left\{ \gamma \mid A_1 \gamma = \mu^1 \right\},
&
\Ccal_2 &= \left\{ \gamma \mid A_2 \gamma = \mu^2 \right\}.
\end{align*}
\pause
Kullback--Leibler divergence:
\begin{equation*}\label{KL}
\KL(\gamma,\xi) = \sum_{i,j} \gamma_{i,j} \left( \log \left( \frac{\gamma_{i,j}}{\xi_{i,j}} \right) -1  \right) + \sum_{i,j} \xi_{i,j}
\end{equation*}
\end{frame}


\begin{frame}{Bregman projections}
	
Bregman projection onto $\Ccal$:
\[
P_{\Ccal}(\xi) := \argmin_{\gamma \in \Ccal} \KL(\gamma,\xi).
\]
\pause
Setting $\gamma^0 = e^{-c/\epsilon}$:
\begin{align*}
\gamma^* = \argmin_{\gamma \in \IR^{n_1 n_2}_+ \cap \Ccal_1 \cap \Ccal_2}
	\scal{c}{\gamma} + \epsilon \KL(\gamma,\One)
\Longleftrightarrow
\gamma^* &= P_{\Ccal_1 \cap \Ccal_2}(\gamma^0)
\end{align*}
\pause
Bregman projection onto $\Ccal_1$ or $\Ccal_2$ $\Longleftrightarrow$ scaling of rows or columns
\begin{align*}\label{scaling}
P_{\Ccal_1}(\gamma) &= \diag(a) \gamma &\text{with}\quad
a &=  {\mu^1}\oslash{A_1 \gamma} \\
P_{\Ccal_2}(\gamma) &= \gamma \diag(b) &\text{with}\quad
b &= {\mu^2}\oslash{A_2 \gamma}\nonumber
\end{align*}

\end{frame}

\begin{frame}{Sinkhorn--Knopp algorithm}
	
	\begin{columns}
	\begin{column}{0.6\textwidth}

	Sinkhorn--Knopp algorithm (SK):
	\[
	\lim P_{\Ccal_2}\circ P_{\Ccal_1} \circ \ldots \circ P_{\Ccal_2} \circ P_{\Ccal_1} (\gamma^0) = \gamma^*
	\]
	
\end{column}

\begin{column}{0.4\textwidth}
	\centering
	\input{schema_a.tex}
\end{column}
\end{columns}
\end{frame}

\begin{frame}{Limitation of the SK algorithm}
Linear convergence rate $1-\eta$, $\eta > 0$.

\begin{columns}
	\begin{column}{0.5\textwidth}
		\centering
		\input{schema_a.tex}\\
		Large $\epsilon$
	\end{column}
	\begin{column}{0.5\textwidth}
		\centering
		\input{schema_b.tex}\\
		Small $\epsilon$
	\end{column}
\end{columns}

Small $\epsilon$ $\Longrightarrow$
very small $\eta$ $\Longrightarrow$
slow convergence
\end{frame}

\subsection{Overrelaxation}
\begin{frame}{Overrelaxation}
	\begin{columns}
		\begin{column}{0.6\textwidth}
			Overrelaxed projections of parameter $\theta \in \IR$:
			\begin{align}\label{or_scaling}
			P_{\Ccal_1}^\theta(\gamma) &= \diag(a)^\theta \gamma\\
			P_{\Ccal_2}^\theta(\gamma) &= \gamma \diag(b)^\theta \nonumber
			\end{align}
			(element-wise exponentiation)
		\end{column}
		\begin{column}{0.4\textwidth}
			\centering
			\input{schema_c.tex}\\
			Typically take $\theta \in [1,2)$.
		\end{column}
	\end{columns}
\end{frame}



\section{Ensuring global convergence}

\iffalse
\subsection[Local rate]{Local rate of convergence}

\begin{frame}{Local study}
		Overrelaxation modifies each eigenvalue of $D_{\gamma^*}(P^\theta_{\Ccal_1} \circ P^\theta_{\Ccal_2})$.
		\begin{center}
			\includegraphics[width=6cm]{images/eigen_transform.png}
		\end{center}
		\pause
		Optimal parameter: $\theta^* = \frac{2}{1+\sqrt{\eta}}$\\
		\pause
		Linear convergence rate: $\frac{1-\sqrt{\eta}}{1+\sqrt{\eta}} \sim 1-2\sqrt{\eta}$
\end{frame}
\fi



\begin{frame}{Algorithm}
How to ensure global convergence?
\pause
\begin{proposition}
Choose $F(\gamma)$ continuous function whose unique minimizer is $\gamma^*$.\\
Choose $\theta_1(\gamma)$, $\theta_2(\gamma)$ continuous functions, such that
\begin{equation}\label{eq:cond_theta_k}
\forall \gamma \notin \Ccal_k,\quad
F(P_{\Ccal_k}^{\theta_k(\gamma)}(\gamma)) < F(\gamma).
\end{equation}
\pause
Alternatively iterate $P_{\Ccal_1}^{\theta_1}$ and $P_{\Ccal_2}^{\theta_2}$, starting from $\gamma^0 = e^{-c/\epsilon}$.\\
This process converges to $\gamma^*$.
\end{proposition}
\end{frame}

\subsection{Lyapunov function}
\begin{frame}{Ensuring global convergence}
	Our choice of Lyapunov function:
	\[F(\gamma) := \KL(\gamma^*,\gamma)\]
	\pause
	
	Motivation of this arbitrary choice:
	\begin{itemize}
		\item makes sense
		\item easy calculation of differences
		\item decreases for \emph{most} $\theta \in [1,2)$ in practice
	\end{itemize}
	
\end{frame}

\begin{frame}{Properties of the Lyapunov function}
Calculating differences:
\begin{equation} \label{eq:kl_diff_scal}
F(\gamma) - F(P^\theta_{\Ccal_k}(\gamma)) = 
\scal{\mu^k}{\varphi_\theta \left((A_k \gamma) \oslash \mu^k \right)},
\end{equation}
where
\begin{equation}
\varphi_\theta(x) = x(1-x^{-\theta}) - \theta \log x
\end{equation}
is a real function, applied coordinate-wise.
\end{frame}

\subsection[Choice of OR parameters]{Choice of overrelaxation parameters}
\begin{frame}{Ensuring the decrease}
\begin{center}
	\vspace*{-0.2cm}\includegraphics[width=4.5cm]{images/cvgce_zone_2.png}\vspace{-0.2cm}\\
	{\small \em Function $\varphi_\theta(x)$ is positive above the red line, negative below.}
\end{center}
\pause
\begin{itemize}
\item Sufficient condition: the smallest  coordinate of $\varphi_\theta \left((A_k \gamma) \oslash \mu^k \right)$ is strictly positive
\pause
\begin{align*}
\Theta^*(u) &:= \max \left\{\theta \mid \varphi_\theta(u) \ge 0 \right\}
&
\Theta(u) &:= clip_{[1,\theta_0]}(\Theta^*(\min u)-\delta)
\end{align*}
\[
\theta_k (\gamma) := \Theta((A_k \gamma) \oslash \mu^k)
\]
\pause
\item $1$D problem of negligible computational cost
\end{itemize}
\end{frame}
\end{document}
